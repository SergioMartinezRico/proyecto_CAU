Sistema de Asistencia Inteligente para Ingenier√≠a (CAU)
Este proyecto implementa un Chatbot de Asistencia T√©cnica basado en Inteligencia Artificial Generativa, dise√±ado espec√≠ficamente para resolver incidencias en un departamento de ingenier√≠a. El sistema gestiona consultas sobre software CAD (Catia/SolidWorks), normativas (ISO/ANSI) y gesti√≥n de licencias.

üìã Descripci√≥n del Proyecto
El sistema integra un modelo de lenguaje grande (LLM) para ofrecer respuestas contextuales y, simult√°neamente, clasificar y estructurar la informaci√≥n de los tickets (categor√≠a, sentimiento y urgencia) en una base de datos relacional.

Caracter√≠sticas principales:

Asistencia Especializada: Entrenado mediante System Prompts para actuar como soporte t√©cnico de ingenier√≠a.

Memoria Conversacional: Uso de LangChain para mantener el contexto de la sesi√≥n.

Salida Estructurada: El LLM responde estrictamente en JSON, permitiendo extraer metadatos anal√≠ticos.

Arquitectura H√≠brida: Desarrollo local en contenedores y despliegue escalable en AWS.

üõ†Ô∏è Stack Tecnol√≥gico
Backend & AI
Lenguaje: Python 3.x

Framework: Flask (API RESTful)

Orquestaci√≥n IA: LangChain

Modelo LLM: LLaMA-3.3-70b (v√≠a Groq API)

Frontend
Tecnolog√≠as: HTML5, CSS3, JavaScript (Vanilla)

Servidor Web: Nginx (Alpine Linux)

Datos & Infraestructura
Base de Datos: PostgreSQL 16.x

DevOps (Local): Docker & Docker Compose

DevOps (Cloud): AWS RDS (PostgreSQL) & AWS EC2 (Ubuntu)

Herramientas: pgAdmin 4, Git

üèóÔ∏è Arquitectura del Sistema
La soluci√≥n sigue una arquitectura desacoplada cliente-servidor:

API Gateway (Flask):

Gestiona el flujo de mensajes y valida sesiones.

Implementa CORS para comunicaci√≥n segura.

Robustez: Mecanismo de limpieza (extraer_json_seguro) para asegurar el parseo de respuestas del LLM.

Interfaz de Usuario (SPA):

Detecci√≥n din√°mica de entorno (Localhost vs AWS IP) para configuraci√≥n autom√°tica de endpoints.

Renderizado visual de estado ("Typing...") y tablas de historial con etiquetas de urgencia.

Base de Datos (Modelo Normalizado):

Dise√±o optimizado con tablas maestras (roles, departments, categories, sentiments, urgencies) para evitar redundancia.

Tabla transaccional interactions que referencia IDs en lugar de texto repetitivo.

üöÄ Instalaci√≥n y Despliegue (Local)
El proyecto est√° contenerizado para facilitar el despliegue local.

Prerrequisitos
Docker Desktop instalado.

API Key de Groq.

Pasos
Clonar el repositorio:

Bash

git clone <url-del-repositorio>
cd <nombre-carpeta>
Configurar variables de entorno: Crea un archivo .env basado en el ejemplo y a√±ade tu API Key:

Fragmento de c√≥digo

GROQ_API_KEY=tu_api_key_aqui
DB_HOST=db
DB_NAME=cau_engineering
...
Iniciar con Docker Compose:

Bash

docker-compose up --build
Frontend disponible en: http://localhost:80

Backend disponible en: http://localhost:5000

pgAdmin disponible en: http://localhost:5050

‚òÅÔ∏è Despliegue en AWS
El entorno de producci√≥n utiliza servicios gestionados para alta disponibilidad.

Database: Amazon RDS (PostgreSQL). Copias de seguridad autom√°ticas y Security Groups estrictos.

App Server: Amazon EC2 (Ubuntu) ejecutando los contenedores de la aplicaci√≥n.

Nota sobre Migraci√≥n de Datos
Para migrar los datos desde el entorno local (Docker) a RDS, se recomienda usar pg_dump y pgAdmin. Importante: Al restaurar en RDS, utilizar la opci√≥n "Do not save owner" para evitar conflictos de permisos entre el usuario root local y el usuario maestro de AWS.

Autor: Sergio Mart√≠nez Rico
